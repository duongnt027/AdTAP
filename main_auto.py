import torch
import os
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import ConcatDataset, DataLoader
import numpy as np
import shutil

from rl import LatentSpaceEnv, PPO
from models import Actor, Critic, CNNAutoEncoder, ResNetEmbedder, ViTransformerDetector
from modules import EarlyStopping, SyntheticDataset
from utils import load_train_test, count_classes, train_cnn_ae, train_detector, load_z_space, Gen_with_PPO, One_Step_To_Feasible_Action, evaluate_model, set_seed

def train_auto(generator, detector, embedder, actor, critic, ppo, env,
                optimizer_d, optimizer_g, criterion_d, early_stopper,
                dataset_name, synthetic_root, model_root, train_path, valid_path,
                num_epochs_generator, num_epochs_detector, num_episodes, num_steps_ppo, num_gen_data, num_epochs_final,
                batch_size, refine_step, device
               ):


    synthetic_dir = f"{synthetic_root}/{dataset_name}"
    os.makedirs(synthetic_dir, exist_ok=True)
    model_dir = f"{model_root}/{dataset_name}"
    os.makedirs(model_dir, exist_ok=True)

    train_dataset, train_loader, test_dataset, test_loader = load_train_test(
        train_path, device=device, batch_size=batch_size, resize=256, ratio_0=1
    )

    synthetic_files = []
    combined_dataset = train_dataset

    for ep in range(num_episodes):
        print(f"\n================ EPISODE {ep+1}/{num_episodes} ================")
        total_class0, total_class1 = count_classes(combined_dataset)

        print(f"[Episode {ep+1}] Class count â†’ 0: {total_class0}, 1: {total_class1}")

        if total_class1 >= total_class0:
            print("Dataset is now balanced. Stopping synthetic generation.")
            break

        # TRAIN GENERATOR
        early_stopper.reset()
        for epoch in range(num_epochs_generator):
            loss_g = train_cnn_ae(generator, train_loader, optimizer_g, device)
            if (epoch + 1) % 10 == 0:
                print(f"[GENERATOR] Epoch {epoch+1}/{num_epochs_generator}, Loss={loss_g:.4f}")
            early_stopper.step(loss_g)
            if early_stopper.early_stop:
                print(f"[GENERATOR] Early stopping at epoch {epoch+1}")
                print(f"[GENERATOR] Epoch {epoch+1}/{num_epochs_generator}, Loss={loss_g:.4f}")
                break

        torch.save(generator.state_dict(), f"{model_dir}/{dataset_name}_generator.pth")

        # TRAIN DETECTOR
        early_stopper.reset()
        for epoch in range(num_epochs_detector):
            loss_d = train_detector(detector, train_loader, optimizer_d, criterion_d, device)
            if (epoch + 1) % 10 == 0:
                print(f"[DETECTOR] Epoch {epoch+1}/{num_epochs_detector}, Loss={loss_d:.4f}")
            early_stopper.step(loss_d)
            if early_stopper.early_stop:
                print(f"[DETECTOR] Early stopping at epoch {epoch+1}")
                print(f"[DETECTOR] Epoch {epoch+1}/{num_epochs_detector}, Loss={loss_d:.4f}")
                break

        torch.save(detector.state_dict(), f"{model_dir}/{dataset_name}_detector.pth")

        # GENERATE SAMPLE CLASS 1
        synthetic_samples = []
        idx_class1 = [i for i, idx_lbl in enumerate(train_dataset.indices) if train_dataset.labels[idx_lbl] == 1]

        ppo_gen_count = 0
        for _ in range(num_gen_data):
            if not idx_class1:
                break
            rand_idx = np.random.choice(idx_class1)
            x_orig, _ = train_dataset[rand_idx]
            x_adv = None
            if ep != 0:
                x_adv = Gen_with_PPO(actor, generator, x_orig, device, ep+1, refine_step)
            if x_adv is None:
                x_adv = One_Step_To_Feasible_Action(generator, detector, x_orig, device)
            else:
                ppo_gen_count += 1
            synthetic_samples.append(x_adv.to(device))

        ppo_gen_rate  = (ppo_gen_count / num_gen_data) * 100
        print(f"{ppo_gen_rate:.2f}% of data generated by PPO strategy")
        
        syn_tensor = torch.cat(synthetic_samples)            
        syn_tensor_hwc = syn_tensor.permute(0,2,3,1).cpu().numpy()   
        syn_labels = np.ones(len(synthetic_samples), dtype=np.float32)

        syn_path = f"{synthetic_dir}/syn_ep{ep+1}.npz"
        np.savez_compressed(syn_path, images=syn_tensor_hwc, labels=syn_labels)
        synthetic_files.append(syn_path)

        print(f"[EP {ep+1}] Generated synthetic saved:", syn_path)

        synthetic_subsets = []
        for f in synthetic_files:
            synthetic_subsets.append(SyntheticDataset(f, device))

        synthetic_full = ConcatDataset(synthetic_subsets)
        combined_dataset = ConcatDataset([train_dataset, synthetic_full])

        train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)

        Z_ppo, Y_ppo = load_z_space(generator, train_loader, device)

        # TRAIN PPO
        env.set_data(Z_ppo, Y_ppo)
        early_stopper.reset()
        
        for step in range(num_steps_ppo):
        
            _ = ppo.collect_trajectories(
                num_episodes=4
            )
        
            a_loss, c_loss, avg_reward = ppo.learn()
        
            if (step + 1) % 1 == 0:
                print(
                    f"Step {step+1:03d} | "
                    f"Actor Loss = {a_loss:.4f}, "
                    f"Critic Loss = {c_loss:.4f}, "
                    f"AvgReward = {avg_reward:.4f}"
                )
        
            early_stopper.step(-avg_reward)
            if early_stopper.early_stop:
                print(f"[PPO] Early stopping at step {step+1}")
                print(
                    f"Step {step+1:03d} | "
                    f"Actor Loss = {a_loss:.4f}, "
                    f"Critic Loss = {c_loss:.4f}, "
                    f"AvgReward = {avg_reward:.4f}"
                )
                break

        
        print(f"[EP {ep+1}] Train dataset expanded: now {len(combined_dataset)} samples")

    final_detector = ViTransformerDetector(embedder=embedder).to(device)
    final_optimizer = optim.Adam(final_detector.parameters(), lr=1e-3)
    final_criterion = nn.BCELoss()
    early_stopper.reset()

    for epoch in range(num_epochs_final):
        loss = train_detector(final_detector, train_loader, final_optimizer, final_criterion, device)
        print(f"[FINAL DETECTOR] Epoch {epoch+1}/{num_epochs_final}, Loss={loss:.4f}")
        early_stopper.step(loss)
        if early_stopper.early_stop:
            print(f"[FINAL DETECTOR] Early stopping at epoch {epoch+1}")
            print(f"[FINAL DETECTOR] Epoch {epoch+1}/{num_epochs_final}, Loss={loss:.4f}")
            break
    evaluate_model(final_detector, test_loader, device, threshold=0.3)

    _, eval_train_loader, _, _ = load_train_test(
        train_path, device=device, batch_size=100, test_size=0
    )
    evaluate_model(final_detector, eval_train_loader, device, threshold=0.3)

    _, eval_valid_loader, _, _ = load_train_test(
        valid_path, device=device, batch_size=100, test_size=0
    )
    evaluate_model(final_detector, eval_valid_loader, device, threshold=0.3)

    torch.save(final_detector.state_dict(), f"{model_dir}/{dataset_name}_detector_f.pth")
    print(f"Final detector saved to {model_dir}/{dataset_name}_detector_f.pth")

    torch.save(actor.state_dict(), f"{model_dir}/{dataset_name}_actor.pth")
    print(f"PPO Actor saved to {model_dir}/{dataset_name}_actor.pth")

    torch.save(critic.state_dict(), f"{model_dir}/{dataset_name}_critic.pth")
    print(f"PPO Critic saved to {model_dir}/{dataset_name}_critic.pth")

set_seed(11)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

PATIENTCE = 5
BATCH_SIZE = 100
LATENT_DIM = 64
EMBEDDING_DIM = 128
REFINE_STEP = 10

NUM_EPOCHS_GENERATOR = 100
NUM_EPOCHS_DETECTOR = 100
NUM_EPOCHS_FINAL = 100
NUM_EPISODES = 100
NUM_STEPS_PPO = 100
NUM_GEN_DATA = 100

SYNTHETIC_ROOT = f"synthetics/"
os.makedirs(SYNTHETIC_ROOT, exist_ok=True)
MODEL_ROOT = f"models/"
os.makedirs(MODEL_ROOT, exist_ok=True)

benchmarks = ["BMAD-AD", "MVTec-AD", "PKU-AD", "VisA-AD"]
for bench in benchmarks:
    dataset_dir = f"/kaggle/input/anomaly-dataset-npz/npz-dataset/{bench}"
    print("BENCHMARK")
    for dataset_name in os.listdir(dataset_dir):
        train_path = f"{dataset_dir}/{dataset_name}/{bench}_{dataset_name}_train.npz"
        valid_path = f"{dataset_dir}/{dataset_name}/{bench}_{dataset_name}_valid.npz"

        env = LatentSpaceEnv(device=DEVICE, max_steps=REFINE_STEP)
        actor = Actor(latent_dim=LATENT_DIM, hidden=256)
        critic = Critic(latent_dim=LATENT_DIM, hidden=256)
        ppo = PPO(actor=actor, critic=critic, env=env, lr=3e-4, gamma=0.99, lam=0.95, clip_eps=0.2, device=DEVICE)

        embedder = ResNetEmbedder(output_dim=EMBEDDING_DIM).to(DEVICE)
        generator = CNNAutoEncoder(latent_dim=LATENT_DIM).to(DEVICE)
        detector = ViTransformerDetector(embedder=embedder).to(DEVICE)
        early_stopper = EarlyStopping(patience=PATIENTCE)

        optimizer_g = optim.Adam(generator.parameters(), lr=1e-4)
        optimizer_d = optim.Adam(detector.parameters(), lr=1e-4)
        criterion_d = nn.BCELoss()

        train_auto(generator, detector, embedder, actor, critic, ppo, env,
                optimizer_d, optimizer_g, criterion_d, early_stopper,
                dataset_name, SYNTHETIC_ROOT, MODEL_ROOT, train_path, valid_path,
                NUM_EPOCHS_GENERATOR, NUM_EPOCHS_DETECTOR, NUM_EPISODES, NUM_STEPS_PPO, NUM_GEN_DATA, NUM_EPOCHS_FINAL,
                BATCH_SIZE, REFINE_STEP, DEVICE
                )






